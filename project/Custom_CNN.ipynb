{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flags\n",
    "DISABLE_CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dims_list = [32, 64, 128, 256, 512]\n",
    "lr = [0.001, 0.0001, 0.00001]\n",
    "train_test_ratio = 0.8\n",
    "\n",
    "# Declare important file paths\n",
    "notebook_path = os.path.abspath(\"Custom_CNN.ipynb\")\n",
    "data_path = os.path.dirname(notebook_path) + '/data/columbia-prcg-datasets/'\n",
    "model_path = os.path.dirname(notebook_path) + '/model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Running on CUDA!\n"
    }
   ],
   "source": [
    "# Select accelerator device\n",
    "def get_default_device():\n",
    "    \"\"\"Returns device, is_cuda (bool).\"\"\"\n",
    "    if not DISABLE_CUDA and torch.cuda.is_available():\n",
    "        print(\"Running on CUDA!\")\n",
    "        return torch.device('cuda'), True\n",
    "    else:\n",
    "        print(\"Running on CPU!\")\n",
    "        return torch.device('cpu'), False\n",
    "device, using_cuda = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_data(input_dim):\n",
    "    # Transform the data\n",
    "    transform = transforms.Compose([\n",
    "                        transforms.Resize((input_dim, input_dim)),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    # Create training/testing dataloaders\n",
    "    full_set = datasets.ImageFolder(root=data_path, transform=transform)\n",
    "    train_size = int(train_test_ratio * len(full_set))\n",
    "    val_size = int((len(full_set) - train_size) / 2)\n",
    "    test_size = len(full_set) - train_size - val_size\n",
    "    train_set, val_set, test_set = torch.utils.data.random_split(full_set, [train_size, val_size, test_size])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_set, shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "    # train_data_in_memory = load_data_into_memory(train_loader)\n",
    "    # val_data_in_memory = load_data_into_memory(val_loader)\n",
    "    # return train_data_in_memory, val_data_in_memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load data into memory to elimate read bottleneck\n",
    "# def load_data_into_memory(data_loader):\n",
    "#     output = []\n",
    "#     for data in data_loader:\n",
    "#         inputs = data[0].to(device, non_blocking=True)\n",
    "#         labels = data[1].to(device, non_blocking=True)\n",
    "#         output.append((inputs, labels))\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare our model architecture\n",
    "def declare_model(input_dim):\n",
    "    class ConvNet(nn.Module):  # Convolutional Neural Network\n",
    "        def __init__(self):\n",
    "            super(ConvNet, self).__init__()\n",
    "            self.layer1 = nn.Sequential(\n",
    "                nn.Conv2d(3, 32, kernel_size=5, stride=2, padding=2),  # (512, 512, 32) (256, 256, 32)\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2))  # (256, 256, 32)\n",
    "            self.layer2 = nn.Sequential(\n",
    "                nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=2),  # (256, 256, 64)\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2))  #  (128, 128, 64)\n",
    "            self.layer3 = nn.Sequential(\n",
    "                nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),  # (512, 512, 64)\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2))  #  (64, 64, 64)\n",
    "    #         self.drop_out = nn.Dropout(0.1)\n",
    "            self.fc1 = nn.Linear(int(input_dim/8) * int(input_dim/8) * 8, 32)\n",
    "            self.fc2 = nn.Linear(32, 1)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            \n",
    "        def forward(self, x):\n",
    "            # print (x.shape)\n",
    "            out = self.layer1(x)\n",
    "            # print (out.shape)\n",
    "            out = self.layer2(out)\n",
    "            # print (out.shape)\n",
    "            out = self.layer3(out)\n",
    "            # print (out.shape)\n",
    "            out = out.reshape(out.size(0), -1)\n",
    "            # print (out.shape)\n",
    "    #         out = self.drop_out(out)\n",
    "            out = self.fc1(out)\n",
    "            # print (out.shape)\n",
    "            out = self.fc2(out)\n",
    "            out = self.sigmoid(out)\n",
    "            return out\n",
    "\n",
    "    model = ConvNet()\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loss_fn, optimizer, train_loader, val_loader, num_epochs):\n",
    "    loss_list = []\n",
    "    train_accuracy_list = []\n",
    "    val_accuracy_list = []\n",
    "    t = torch.Tensor([0.5]).to(device)  # 0.5 acts as threshold\n",
    "    # highest_acc = 0.0\n",
    "\n",
    "    torch.backends.cudnn.benchmark = True  # make training faster on Cuda\n",
    "\n",
    "    # start_time = time.time()\n",
    "\n",
    "    model.train()  # switch to train mode\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train the model\n",
    "        running_loss = 0.0\n",
    "        train_correct = train_total = 0 \n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.view(-1,1)\n",
    "\n",
    "            probs = model(inputs)\n",
    "\n",
    "            outputs = (probs > t).float() * 1  # obtain train accuracies\n",
    "            train_total += len(outputs)\n",
    "            train_correct += (outputs == labels.float()).float().sum() / len(outputs)  # normalize batch size\n",
    "\n",
    "            loss = loss_fn(probs, labels.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # if False and (i + 1) % 400 == 0:\n",
    "            #     print ('# Images: {:} | Loss: {:.6f} | Time: {:.6f}'.format(i + 1, running_loss / (i + 1), time.time() - start_time))\n",
    "        train_accuracy = train_correct / train_total\n",
    "            \n",
    "        # Test current version of model to obtain accuracy    \n",
    "        val_correct = val_total = 0 \n",
    "        with torch.no_grad():\n",
    "            for (inputs, labels) in val_loader:\n",
    "                labels = labels.view(-1,1)\n",
    "\n",
    "                probs = model(inputs)\n",
    "                outputs = (probs > t).float() * 1\n",
    "                val_total += len(outputs)\n",
    "                val_correct += (outputs == labels.float()).float().sum() / len(outputs)  # normalize batch size\n",
    "        val_accuracy = val_correct / val_total\n",
    "\n",
    "        # if val_accuracy > highest_acc:  # save highest accuracy model\n",
    "        #     highest_acc = val_accuracy\n",
    "        #     torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        loss_list.append(running_loss)\n",
    "        train_accuracy_list.append(train_accuracy)\n",
    "        val_accuracy_list.append(val_accuracy)\n",
    "        # print ('Epoch: {:} | Time (m): {:.6f} | Loss: {:.6f} | Train Accuracy: {:.8%} | Validation Accuracy: {:.8%}'.format(\n",
    "        #     epoch, (time.time() - start_time)/60, running_loss, train_accuracy, val_accuracy))\n",
    "\n",
    "    return loss_list, train_accuracy_list, val_accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "torch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\ntorch.Size([1, 3, 64, 64])\ntorch.Size([1, 32, 16, 16])\ntorch.Size([1, 64, 4, 4])\ntorch.Size([1, 128, 2, 2])\ntorch.Size([1, 512])\ntorch.Size([1, 32])\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-4e9a36de40fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_accuracy_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mrun_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-36-4e9a36de40fa>\u001b[0m in \u001b[0;36mrun_experiment\u001b[1;34m(input_dim, lr)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mloss_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_accuracy_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_accuracy_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-8901a85e8561>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, loss_fn, optimizer, train_loader, val_loader, num_epochs)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mtrain_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m    137\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    928\u001b[0m         \"\"\"\n\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    931\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"P\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    233\u001b[0m                         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m                                 \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecodermaxblock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m                             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstruct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m                                 \u001b[1;31m# truncated png/gif\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\JpegImagePlugin.py\u001b[0m in \u001b[0;36mload_read\u001b[1;34m(self, read_bytes)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[0mso\u001b[0m \u001b[0mlibjpeg\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mfinish\u001b[0m \u001b[0mdecoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \"\"\"\n\u001b[1;32m--> 399\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mImageFile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLOAD_TRUNCATED_IMAGES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_experiment(input_dim, lr):\n",
    "    train_loader, val_loader = obtain_data(input_dim)\n",
    "\n",
    "    model = declare_model(input_dim)\n",
    "    # Define the loss function and optimizer\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "    loss_list, train_accuracy_list, val_accuracy_list = train_model(model, loss_fn, optimizer, train_loader, val_loader, num_epochs=1)\n",
    "    return loss_list, train_accuracy_list, val_accuracy_list\n",
    "\n",
    "run_experiment(64, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Custom_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}