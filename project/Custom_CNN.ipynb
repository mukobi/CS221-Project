{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim_h = 512\n",
    "input_dim_w = 512\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                    transforms.Resize((input_dim_w, input_dim_h)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "notebook_path = os.path.abspath(\"Custom_CNN.ipynb\")\n",
    "data_path = os.path.dirname(notebook_path) + '/data/columbia-prcg-datasets/'\n",
    "\n",
    "full_set = datasets.ImageFolder(root=data_path, transform=transform)\n",
    "train_size = int(0.8 * len(full_set))\n",
    "test_size = len(full_set) - train_size\n",
    "train_set, test_set = torch.utils.data.random_split(full_set, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, shuffle=True, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2),  # (1024, 1024, 3) -> (32, 32, 32)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))  # (512, 512, 32)\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),  # (16, 16, 64)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))  #  (256, 256, 64)\n",
    "        # self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(128 * 128 * 64, 1)\n",
    "        # self.fc1 = nn.Linear(128 * 128 * 64, 1000)\n",
    "        # self.fc2 = nn.Linear(1000, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        # out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        # out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])) is deprecated. Please ensure they have the same size.\n  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n0.0\n10.047644181685014\n15.78915514264788\n16.935142209452966\n14.8264017802913\n15.169972588034238\n13.136059401465245\n13.231756774472519\n13.644948888708043\n13.360054351471282\n13.678723514670192\n13.44211856738941\n13.016266326273769\n13.710048835696155\n13.325599021099983\n13.175056609096906\n12.871593866289032\n13.24996352614018\n13.1285516517597\n13.019853062654665\n12.921970253560081\n12.96431814437794\n13.002833646886488\n13.396858908913352\n13.528881896086254\n13.760468874319615\n13.762577758438285\n13.968449983209702\n13.963007305864762\n13.862986731775027\n14.136801697487055\n14.037625070553501\n14.03070562130937\n13.940726859331852\n13.774996055535906\n13.933592038276869\n13.930321088458031\n14.150657910863666\n14.286906129731907\n14.416185130243717\n14.470111009783281\n14.454183996158795\n14.504645490306574\n14.424547186583764\n14.4107368365437\n14.336272795818862\n14.145165019335302\n14.255495168600872\n14.303792834529757\n14.237573196348979\n14.17399705669837\n13.950691872613538\n14.001131815553398\n13.997636126933125\n14.045343645839726\n13.890731316512813\n13.790884170940215\n13.694534298417446\n13.649058813072113\n13.651875258702312\n13.746548133761236\n13.747676818148399\n13.704274753441558\n13.706037605999011\n/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:802: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n  warnings.warn(str(msg))\n13.750851573140684\n13.751844801661056\n13.669204281967094\n13.79492131501836\n13.957520405101356\n13.955465272608093\n13.953468774422769\n13.834941847917904\n13.758025961676186\n13.834410217326903\n13.834155163784258\n13.797114597020867\n13.797356333588489\n13.905105501761232\n13.90395832183877\n/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:784: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 6. Skipping tag 41486\n  \" Skipping tag %s\" % (size, len(data), tag)\n/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:784: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 41487\n  \" Skipping tag %s\" % (size, len(data), tag)\n13.86790838856462\n13.970741207680005\n14.036967765535291\n14.00061503513722\n14.03163787346024\n13.963358070564043\n13.96162073424504\n14.02410731166082\n14.148605727711447\n14.113461605942344\n14.110117600823092\n14.076180763964382\n14.073319402667485\n14.04051906821782\n13.949065633542299\n13.977009812779684\n13.975311610224871\n13.944896386391662\n13.88665138189628\n13.914092375962378\n13.885215647646445\n13.856915876939222\n13.82917594343689\n13.88316751156918\n13.936111716595121\n13.96149597387836\n13.933816741014185\n13.932701698684333\n13.905808205698051\n13.879412279649536\n13.90415289028318\n13.953540375836864\n14.002038797744216\n14.049671948966333\n13.998740335358233\n14.021350962566139\n13.971550402073731\n13.994005720744761\n13.992481425519076\n13.944190358832971\n13.966309775633535\n13.965054163428567\n13.941002589823489\n13.962604639864084\n13.938963729709654\n13.893438691193783\n13.870728618521198\n13.89220272067234\n13.935078506109566\nLoss: 17877.27091026306     Accuracy: 0.5218750238418579\n"
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    # Train the model\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for i, [inputs, labels] in enumerate(train_loader):   \n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 10 == 1:\n",
    "            print (running_loss / i)\n",
    "        \n",
    "    # Test current version of model to obtain accuracy    \n",
    "    correct = total = 0 \n",
    "    with torch.no_grad():\n",
    "        for [inputs, labels] in test_loader:   \n",
    "            probs = model(inputs)\n",
    "            t = torch.Tensor([0.5])  # 0.5 acts as threshold\n",
    "            outputs = (probs > t).float() * 1\n",
    "            total += len(outputs)\n",
    "            correct += (outputs == labels.float()).float().sum()\n",
    "            \n",
    "    accuracy = correct / total\n",
    "    print ('Loss: {}     Accuracy: {}'.format(running_loss,  accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Accuracy of the network on the 10000 test images: 52 %\n"
    }
   ],
   "source": [
    "correct = total = 0 \n",
    "with torch.no_grad():\n",
    "    for [inputs, labels] in test_loader:   \n",
    "        probs = model(inputs)\n",
    "        t = torch.Tensor([0.5])  # 0.5 acts as threshold\n",
    "        outputs = (probs > t).float() * 1\n",
    "        total += len(outputs)\n",
    "        correct += (outputs == labels.float()).float().sum()\n",
    "\n",
    "accuracy = correct / total\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "xRiWWUjAtLgf",
    "outputId": "f864913c-5715-4ca2-d949-a53e9abcf543"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n",
      "320\n"
     ]
    }
   ],
   "source": [
    "print (len(train_loader))\n",
    "print (len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gqsSnvVUswLn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Custom_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}