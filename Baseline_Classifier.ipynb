{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline_Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7TP9MRLEe-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edYN5FFmQmDQ",
        "colab_type": "code",
        "outputId": "68d23cc6-e6bf-4121-9e82-2dd495dae367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECHScoN_JFhy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "                    transforms.Resize((32,32)),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "root = \"/content/drive/My Drive/Colab Notebooks/CS221/dataset\"\n",
        "full_set = datasets.ImageFolder(root=root, transform=transform)\n",
        "train_size = int(0.8 * len(full_set))\n",
        "test_size = len(full_set) - train_size\n",
        "train_set, test_set = torch.utils.data.random_split(full_set, [train_size, test_size])\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, shuffle=True, num_workers=1)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, shuffle=False, num_workers=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72uPDJvPElfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()      \n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 2)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.softmax(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkQfTluyFW_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR1_K92OFZBw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "027da4cd-27b5-4a0a-a8e0-eeb415aa924a"
      },
      "source": [
        "for epoch in range(1):  # loop over the dataset multiple times\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "    \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 20 == 19:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 20))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    20] loss: 0.705\n",
            "[1,    40] loss: 0.697\n",
            "[1,    60] loss: 0.703\n",
            "[1,    80] loss: 0.687\n",
            "[1,   100] loss: 0.699\n",
            "[1,   120] loss: 0.690\n",
            "[1,   140] loss: 0.691\n",
            "[1,   160] loss: 0.691\n",
            "[1,   180] loss: 0.697\n",
            "[1,   200] loss: 0.702\n",
            "[1,   220] loss: 0.683\n",
            "[1,   240] loss: 0.681\n",
            "[1,   260] loss: 0.668\n",
            "[1,   280] loss: 0.697\n",
            "[1,   300] loss: 0.678\n",
            "[1,   320] loss: 0.686\n",
            "[1,   340] loss: 0.718\n",
            "[1,   360] loss: 0.680\n",
            "[1,   380] loss: 0.697\n",
            "[1,   400] loss: 0.683\n",
            "[1,   420] loss: 0.681\n",
            "[1,   440] loss: 0.669\n",
            "[1,   460] loss: 0.659\n",
            "[1,   480] loss: 0.701\n",
            "[1,   500] loss: 0.635\n",
            "[1,   520] loss: 0.673\n",
            "[1,   540] loss: 0.606\n",
            "[1,   560] loss: 0.732\n",
            "[1,   580] loss: 0.693\n",
            "[1,   600] loss: 0.672\n",
            "[1,   620] loss: 0.640\n",
            "[1,   640] loss: 0.648\n",
            "[1,   660] loss: 0.662\n",
            "[1,   680] loss: 0.747\n",
            "[1,   700] loss: 0.713\n",
            "[1,   720] loss: 0.658\n",
            "[1,   740] loss: 0.620\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,   760] loss: 0.700\n",
            "[1,   780] loss: 0.592\n",
            "[1,   800] loss: 0.708\n",
            "[1,   820] loss: 0.695\n",
            "[1,   840] loss: 0.603\n",
            "[1,   860] loss: 0.619\n",
            "[1,   880] loss: 0.657\n",
            "[1,   900] loss: 0.727\n",
            "[1,   920] loss: 0.691\n",
            "[1,   940] loss: 0.664\n",
            "[1,   960] loss: 0.542\n",
            "[1,   980] loss: 0.520\n",
            "[1,  1000] loss: 0.593\n",
            "[1,  1020] loss: 0.559\n",
            "[1,  1040] loss: 0.585\n",
            "[1,  1060] loss: 0.633\n",
            "[1,  1080] loss: 0.628\n",
            "[1,  1100] loss: 0.486\n",
            "[1,  1120] loss: 0.616\n",
            "[1,  1140] loss: 0.518\n",
            "[1,  1160] loss: 0.722\n",
            "[1,  1180] loss: 0.620\n",
            "[1,  1200] loss: 0.611\n",
            "[1,  1220] loss: 0.707\n",
            "[1,  1240] loss: 0.488\n",
            "[1,  1260] loss: 0.728\n",
            "[1,  1280] loss: 0.724\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpRGUO9lFbHV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8ef76ce2-d573-46ab-8a72-b4be527a8910"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:742: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 6. Skipping tag 41486\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 41487\n",
            "  \" Skipping tag %s\" % (size, len(data), tag))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 65 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0nbYfT8GWA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}